{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 개발환경(OS) : colab(Linux)"
      ],
      "metadata": {
        "id": "NhZM20TB8DAH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# python==3.7.12\n",
        "# albumentations==1.1.0\n",
        "# numpy==1.19.5\n",
        "# pandas==1.3.5\n",
        "# cv2==4.1.2\n",
        "# sklearn==1.0.2\n",
        "# json==2.0.9\n",
        "# torch==1.10.0+cu111\n",
        "# timm==0.5.4\n",
        "# transformers==4.16.2"
      ],
      "metadata": {
        "id": "_4N2xa4IQ091"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zvzCS3uMNta"
      },
      "outputs": [],
      "source": [
        "# import google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6oNvWEsOh0w"
      },
      "outputs": [],
      "source": [
        "# pakage\n",
        "\n",
        "!pip uninstall opencv-python-headless==4.5.5.62 --yes\n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "\n",
        "import pickle\n",
        "import gc\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import random\n",
        "import os\n",
        "import json \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# timm : 0.5.4\n",
        "!pip install timm\n",
        "# albumtations : 1.1.0\n",
        "!pip install -U albumentations\n",
        "# transformers : 4.16.2\n",
        "!pip install transformers\n",
        "\n",
        "import timm\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from albumentations import (\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
        ")\n",
        "from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHMBNZljMqmP"
      },
      "outputs": [],
      "source": [
        "# unzip train data\n",
        "\n",
        "!unzip \"/content/drive/MyDrive/Dacon/농업 환경 변화에 따른 작물 병해 진단 AI 경진대회/data/train.zip\"\n",
        "!unzip \"/content/drive/MyDrive/Dacon/농업 환경 변화에 따른 작물 병해 진단 AI 경진대회/data/test.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7uG8HgZwL4Wl"
      },
      "outputs": [],
      "source": [
        "# get sequence feature information\n",
        "\n",
        "csv_feature_dict = {'내부 습도 1 최고': [25.9, 100.0],\n",
        "                    '내부 습도 1 최저': [0.0, 100.0],\n",
        "                    '내부 습도 1 평균': [23.7, 100.0],\n",
        "                    '내부 온도 1 최고': [3.4, 47.6],\n",
        "                    '내부 온도 1 최저': [3.3, 47.0],\n",
        "                    '내부 온도 1 평균': [3.4, 47.3],\n",
        "                    '내부 이슬점 최고': [0.2, 34.7],\n",
        "                    '내부 이슬점 최저': [0.0, 34.4],\n",
        "                    '내부 이슬점 평균': [0.1, 34.5]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y8cT9SsD5HIS"
      },
      "outputs": [],
      "source": [
        "# label encoder, decoder \n",
        "\n",
        "train_json = sorted(glob('train/*/*.json'))\n",
        "\n",
        "labels = []\n",
        "for i in range(len(train_json)):\n",
        "    with open(train_json[i], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "        crop = sample['annotations']['crop']\n",
        "        disease = sample['annotations']['disease']\n",
        "        risk = sample['annotations']['risk']\n",
        "        label=f\"{crop}_{disease}_{risk}\"\n",
        "        labels.append(label)\n",
        "\n",
        "label_encoder = sorted(np.unique(labels))\n",
        "label_encoder = {key:value for key,value in zip(label_encoder, range(len(label_encoder)))}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F6fzFlDiXZNi"
      },
      "outputs": [],
      "source": [
        "# hyper parameters\n",
        "\n",
        "opt = dict()\n",
        "\n",
        "opt['batch_size'] = 16\n",
        "opt['class_n'] = len(label_encoder)\n",
        "opt['lr'] = 2e-4\n",
        "opt['embedding_dim'] = 512\n",
        "opt['feature_n'] = len(csv_feature_dict)\n",
        "opt['max_len'] = 300\n",
        "opt['dropout_rate'] = 0.3\n",
        "opt['epoch_n'] = 25\n",
        "opt['vision_pretrain'] = True\n",
        "opt['worker_n'] = 8\n",
        "opt['folder'] = 'model_weights'\n",
        "opt['bidirectional'] = True\n",
        "opt['minmax_dict'] = csv_feature_dict\n",
        "opt['label_dict'] = label_encoder\n",
        "opt['enc_name'] = 'resnext50_32x4d'\n",
        "opt['enc_dim'] = 2048\n",
        "opt['dec_dim'] = 1024\n",
        "opt['img_size1'] = 384\n",
        "opt['img_size2'] = 384\n",
        "opt['precision'] = 'amp'\n",
        "opt['seed'] = 42\n",
        "opt['mix'] = 'cutmix'\n",
        "opt['mix_prob'] = 0.3\n",
        "opt['mean'] = [0.485, 0.456, 0.406]\n",
        "opt['std'] = [0.229, 0.224, 0.225]\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NwC5Ii5fwQAz"
      },
      "outputs": [],
      "source": [
        "# fix seed\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(opt['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bbS-2KkCUd5R"
      },
      "outputs": [],
      "source": [
        "# cutmix function\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix(data, target, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_target = target[indices]\n",
        "\n",
        "    lam = np.clip(np.random.beta(alpha, alpha),0.3,0.4)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    new_data = data.clone()\n",
        "    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n",
        "    # adjust lambda to exactly match pixel ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "    targets = (target, shuffled_target, lam)\n",
        "\n",
        "    return new_data, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "88ophtlaV_7g"
      },
      "outputs": [],
      "source": [
        "# get data\n",
        "\n",
        "train = sorted(glob('train/*'))\n",
        "test = sorted(glob('test/*'))\n",
        "labelsss = pd.read_csv('/content/drive/MyDrive/Dacon/농업 환경 변화에 따른 작물 병해 진단 AI 경진대회/data/train.csv')['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7Xvkqaj7GeJ5"
      },
      "outputs": [],
      "source": [
        "# k-fold cross validation\n",
        "\n",
        "skf = StratifiedKFold(n_splits = 5)\n",
        "train = shuffle(train, random_state=opt['seed'])\n",
        "\n",
        "folds = []\n",
        "for idx, (train_idx, val_idx) in enumerate(skf.split(train, labelsss)):\n",
        "    folds.append((train_idx, val_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mvYENzv1L4Wo"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "\n",
        "def trainTransform():\n",
        "  return Compose([\n",
        "                  Transpose(p=0.5),\n",
        "                  HorizontalFlip(p=0.5),\n",
        "                  VerticalFlip(p=0.5),\n",
        "                  ShiftScaleRotate(p=0.5),\n",
        "                  RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "                  Resize(opt['img_size1'], opt['img_size2']),\n",
        "                  Normalize(mean=opt['mean'], std=opt['std'], max_pixel_value=255.0, p=1.0),\n",
        "                  ToTensorV2(p=1.0),\n",
        "                  ], p=1.)\n",
        "  \n",
        "def valTransform():\n",
        "  return Compose([\n",
        "                  Resize(opt['img_size1'], opt['img_size2']),\n",
        "                  Normalize(mean=opt['mean'], std=opt['std'], max_pixel_value=255.0, p=1.0),\n",
        "                  ToTensorV2(p=1.0),\n",
        "              ], p=1.)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, opt, files, mode, transforms):\n",
        "        self.files = files\n",
        "        self.mode = mode\n",
        "        self.transforms = transforms\n",
        "        self.csv_check = [0]*len(self.files)\n",
        "        self.seq = [None]*len(self.files)\n",
        "        self.minmax_dict = opt['minmax_dict']\n",
        "        self.max_len = opt['max_len']\n",
        "        self.label_encoder = opt['label_dict']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        file = self.files[i]\n",
        "        file_name = file.split('/')[-1]\n",
        "        \n",
        "        if self.csv_check[i] == 0:\n",
        "            csv_path = f'{file}/{file_name}.csv'\n",
        "            df = pd.read_csv(csv_path)\n",
        "            try:\n",
        "                estiTime1, estiTime2 = df.iloc[0]['측정시각'], df.iloc[1]['측정시각']\n",
        "            except:\n",
        "                estiTime1, estiTime2 = 0, 1\n",
        "\n",
        "            df = df[self.minmax_dict.keys()]\n",
        "            df = df.replace('-', 0)\n",
        "            \n",
        "            if self.mode == 'train':\n",
        "                decision = np.random.rand()\n",
        "                if estiTime1==estiTime2 and len(df)>400:\n",
        "                    if decision > 0.5:\n",
        "                        df = df[0::2].reset_index(drop=True)\n",
        "                    else:\n",
        "                        df = df[1::2].reset_index(drop=True)\n",
        "            else: \n",
        "                if estiTime1==estiTime2 and len(df)>400:\n",
        "                    df = df[0::2].reset_index(drop=True)\n",
        "                \n",
        "            \n",
        "            # minmax-scaling\n",
        "            for col in df.columns:\n",
        "                df[col] = df[col].astype(float) - self.minmax_dict[col][0]\n",
        "                df[col] = df[col] / (self.minmax_dict[col][1]-self.minmax_dict[col][0])\n",
        "\n",
        "            # zero-padding\n",
        "            pad = np.zeros((self.max_len, len(df.columns)))\n",
        "            length = min(self.max_len, len(df))\n",
        "            pad[-length:] = df.to_numpy()[-length:]\n",
        "\n",
        "            # transpose-to-sequential-data\n",
        "            seq = torch.tensor(pad, dtype=torch.float32)\n",
        "            self.seq[i] = seq\n",
        "            self.csv_check[i] = 1\n",
        "        else:\n",
        "            seq = self.seq[i]\n",
        "        \n",
        "        # image-transform\n",
        "        image_path = f'{file}/{file_name}.jpg'\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.uint8)              \n",
        "        img = self.transforms(image=img)['image'] \n",
        "\n",
        "        \n",
        "        if self.mode == 'train' or self.mode == 'val':\n",
        "            json_path = f'{file}/{file_name}.json'\n",
        "            with open(json_path, 'r') as f:\n",
        "                json_file = json.load(f)\n",
        "            \n",
        "            crop = json_file['annotations']['crop']\n",
        "            disease = json_file['annotations']['disease']\n",
        "            risk = json_file['annotations']['risk']\n",
        "            label = torch.tensor(self.label_encoder[f'{crop}_{disease}_{risk}'], dtype=torch.long)\n",
        "            \n",
        "            return img, seq, label\n",
        "        else:\n",
        "            return img, seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y8qmkUoRL4Wt"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = timm.create_model(model_name=opt['enc_name'], \n",
        "                                       pretrained=opt['vision_pretrain'], \n",
        "                                       num_classes=0)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        output = self.model(inputs)\n",
        "        return output\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder = nn.GRU(opt['feature_n'], opt['embedding_dim'], bidirectional = opt['bidirectional'])\n",
        "        self.dense = nn.Linear(2*opt['max_len']*opt['embedding_dim'], opt['dec_dim'])\n",
        "        \n",
        "        self.f1 = nn.Linear(opt['enc_dim']+opt['dec_dim'], opt['enc_dim']+opt['dec_dim'])\n",
        "        self.out = nn.Linear(opt['enc_dim']+opt['dec_dim'], opt['class_n'])\n",
        "        self.dropout = nn.Dropout(opt['dropout_rate'])\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def init_weight(self):\n",
        "        torch.nn.init.xavier_uniform_(self.f1.weight)  \n",
        "        torch.nn.init.xavier_uniform_(self.dense.weight)  \n",
        "        torch.nn.init.xavier_uniform_(self.out.weight)  \n",
        "\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        dec_out, _ = self.decoder(dec_inp)\n",
        "        dec_out = self.dense(dec_out.view(dec_out.size(0), -1))\n",
        "\n",
        "        concat = torch.cat([enc_out, dec_out], dim=1) \n",
        "        concat = self.f1(self.relu(concat))\n",
        "        concat = self.dropout(self.relu(concat))\n",
        "        output = self.out(concat)\n",
        "        return output\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.encoder = Encoder(opt)\n",
        "        self.decoder = Decoder(opt)\n",
        "        self.to(device)\n",
        "        \n",
        "    def forward(self, img, seq):\n",
        "        enc_out = self.encoder(img)\n",
        "        output = self.decoder(enc_out, seq)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PWj3yteRalRB"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "\n",
        "class CustomTrainer:\n",
        "    def __init__(self, model, folder, fold):\n",
        "        self.model=model\n",
        "        \n",
        "        self.save_dir = f'/content/{folder}'\n",
        "        if not os.path.exists(self.save_dir):\n",
        "          os.makedirs(self.save_dir)\n",
        "          \n",
        "        self.optimizer = AdamW(model.parameters(), lr=opt['lr'])\n",
        "        self.scaler = torch.cuda.amp.GradScaler() \n",
        "\n",
        "        total_steps = int(len(train_dataset)*opt['epoch_n']/(opt['batch_size']))\n",
        "        warmup_steps = 1149\n",
        "        print('total_steps: ', total_steps)\n",
        "        print('warmup_steps: ', warmup_steps)\n",
        "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.val_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.best_score = 0.0\n",
        "\n",
        "\n",
        "    def run(self, train_loader, val_loader):\n",
        "        for epoch in range(opt['epoch_n']):\n",
        "            gc.collect()\n",
        "            learning_rate = self.optimizer.param_groups[0]['lr']\n",
        "            print('learning_rate: ', learning_rate)\n",
        "            print(f'----- train, epoch{epoch+1} -----')\n",
        "            train_loss, train_score = self.train_function(train_loader, epoch)\n",
        "            print(' ')\n",
        "            print(f'train_loss: {train_loss:.6f}, train_score: {train_score:.6f}')\n",
        "\n",
        "            print('----------------------------------')\n",
        "\n",
        "            print(f'----- val, epoch{epoch+1} -----')\n",
        "            with torch.no_grad():\n",
        "                val_loss, val_score = self.val_function(val_loader)\n",
        "            print(' ')\n",
        "            print(f'val_loss: {val_loss:.6f}, val_score: {val_score:.6f}')\n",
        "\n",
        "\n",
        "            if epoch+1 >= 16 and val_score >= self.best_score:\n",
        "                torch.save(self.model.state_dict(), self.save_dir+f\"/best-acc-epoch{epoch+1}.bin\")\n",
        "                self.best_score=val_score\n",
        "                print(f'model is saved when epoch is : {epoch+1}')\n",
        "\n",
        "\n",
        "    def train_function(self, train_loader, epoch):\n",
        "        self.model.train()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        total_score = 0.0\n",
        "        for bi, data in enumerate(tqdm(train_loader)):\n",
        "            data = [x.to(device) for x in data]\n",
        "            img, seq, label = data\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            # use mix or not\n",
        "            if opt['mix']!=None and epoch < opt['epoch_n']-10: \n",
        "                mix_decision = np.random.rand()\n",
        "                if opt['mix'] == 'cutmix' and mix_decision < opt['mix_prob']:\n",
        "                    img, mix_labels = cutmix(img, label, 1.0)\n",
        "                else: \n",
        "                  pass\n",
        "            else: mix_decision = 1\n",
        "\n",
        "            if opt['epoch_n']-10 <= epoch:\n",
        "                assert mix_decision == 1\n",
        "            \n",
        "            # use amp or not\n",
        "            if opt['precision'] == 'float':\n",
        "                out = self.model(img, seq)\n",
        "\n",
        "                if mix_decision < opt['mix_prob']:\n",
        "                    loss = self.loss_fn(out, mix_labels[0])*mix_labels[2] + self.loss_fn(out, mix_labels[1])*(1-mix_labels[2])\n",
        "                else:\n",
        "                    loss = self.loss_fn(out, label)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "            else: \n",
        "                with torch.cuda.amp.autocast():\n",
        "                    out = self.model(img, seq)\n",
        "                    if mix_decision < opt['mix_prob']:\n",
        "                        loss = self.loss_fn(out, mix_labels[0])*mix_labels[2] + self.loss_fn(out, mix_labels[1])*(1-mix_labels[2])\n",
        "                    else:\n",
        "                        loss = self.loss_fn(out, label)\n",
        "\n",
        "                self.scaler.scale(loss).backward()  \n",
        "                self.scaler.step(self.optimizer) \n",
        "                self.scaler.update()              \n",
        "            \n",
        "            self.scheduler.step()\n",
        "            total_loss+=loss.detach().cpu()\n",
        "\n",
        "            total_score+=f1_score(label.cpu(), out.argmax(1).cpu(), average='macro')\n",
        "        return total_loss/len(train_loader), total_score/len(train_loader)\n",
        "\n",
        "    def val_function(self, val_loader):\n",
        "        self.model.eval()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        preds, targets = [], []\n",
        "        for bi, data in enumerate(tqdm(val_loader)):\n",
        "            data = [x.to(device) for x in data]\n",
        "            img, seq, label = data\n",
        "\n",
        "            out = self.model(img, seq)\n",
        "            loss = self.val_loss_fn(out, label)\n",
        "\n",
        "            total_loss+=loss.detach().cpu()\n",
        "\n",
        "            pred = out.argmax(1).detach().cpu().tolist()\n",
        "            target = label.reshape(-1).detach().cpu().tolist()\n",
        "\n",
        "            preds.extend(pred)\n",
        "            targets.extend(target)\n",
        "        \n",
        "        score = f1_score(targets, preds, average='macro')\n",
        "        return total_loss/len(val_loader), score\n",
        "\n",
        "    def log(self, message):\n",
        "        with open(self.log_path, 'a+') as logger:\n",
        "            logger.write(f'{message}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yCjToZVTPPI"
      },
      "outputs": [],
      "source": [
        "# run\n",
        "\n",
        "print(opt)\n",
        "for i in range(len(folds)):\n",
        "    train_idx, val_idx = folds[i]\n",
        "    \n",
        "    print(f'{i+1}th fold training is start')\n",
        "    \n",
        "    # data\n",
        "    train_dataset = CustomDataset(opt, np.array(train)[train_idx], mode='train', transforms=trainTransform())\n",
        "    val_dataset = CustomDataset(opt, np.array(train)[val_idx], mode='val', transforms=valTransform())\n",
        "    print('num of train: ', len(train_dataset))\n",
        "    print('num of val: ', len(val_dataset))\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=opt['batch_size'], num_workers=opt['worker_n'], shuffle=True, drop_last=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2*opt['batch_size'], num_workers=opt['worker_n'], shuffle=False)\n",
        "\n",
        "    # model\n",
        "    custom_model = CustomModel(opt)\n",
        "\n",
        "    # trainer\n",
        "    custom_trainer = CustomTrainer(model=custom_model, folder=opt['folder']+f'/fold{i+1}', fold=i+1)\n",
        "    custom_trainer.run(train_dataloader, val_dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "dacon-lg-code 모델 생성 및 학습 코드",
      "provenance": []
    },
    "interpreter": {
      "hash": "8207dccf39e710c758db0a3115e8b6364f9af698460a2f758c1d8836f75fc2ad"
    },
    "kernelspec": {
      "display_name": "eunil_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
